{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "mini_project_V.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJGZv6FSY5rd"
      },
      "source": [
        "## Language Translator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcLCZ5WGY5rf"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MmsL-9aY5rl"
      },
      "source": [
        "From `nltk` we can download translated sentences between different languages. You can see the example between **English and French** below but feel free to try different combination as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpIlAEd8Y5rv"
      },
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras,tensorflow\n",
        "import io\n",
        "import re\n",
        "import string\n",
        "from unicodedata import normalize\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv6CTnEibKH1",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ec561d8e-ae6a-4b94-c0d6-69ebf575ef26"
      },
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2b202af1-f917-4fd4-a338-f3b9f3fa99ae\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2b202af1-f917-4fd4-a338-f3b9f3fa99ae\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving bilingual_pairs.txt to bilingual_pairs.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbDvNWoebOqb"
      },
      "source": [
        "#function to read the file\n",
        "def read_data(file):\n",
        "  data = []\n",
        "  with open(file) as file:\n",
        "    for entry in file:\n",
        "      entry = entry.strip()\n",
        "      data.append(entry)\n",
        "    return data\n",
        "#saving the data\n",
        "data = read_data('bilingual_pairs.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TGGGwDorLh7"
      },
      "source": [
        "data = data[:140000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m36ONk53w7If"
      },
      "source": [
        "#make english and french arrays\n",
        "def build_english_french_sentences(data):\n",
        "  english_sentences=[]\n",
        "  french_sentences=[]\n",
        "  for line in data:\n",
        "    english = line.split('\\t')[0]\n",
        "    french = line.split('\\t')[1]\n",
        "    english_sentences.append(english)\n",
        "    french_sentences.append(french)\n",
        "  return english_sentences, french_sentences\n",
        "#calling the function\n",
        "english_sentences, french_sentences = build_english_french_sentences(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPwTOYdZxacr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb4ee3f-1adc-42f8-a62c-41ba1bf1d60b"
      },
      "source": [
        "print('english_sentences: ',english_sentences[:5])\n",
        "print('---'*30)\n",
        "print('french_sentences: ',french_sentences[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english_sentences:  ['Go.', 'Run!', 'Run!', 'Wow!', 'Fire!']\n",
            "------------------------------------------------------------------------------------------\n",
            "french_sentences:  ['Va !', 'Cours\\u202f!', 'Courez\\u202f!', 'Ã‡a alors\\u202f!', 'Au feu !']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBwzqyUSy9IS"
      },
      "source": [
        "#function to clean the sentences\n",
        "def clean_sentences(sentence):\n",
        " # prepare regex for char filtering\n",
        " re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        " # prepare translation table for removing punctuation\n",
        " table = str.maketrans('', '', string.punctuation)\n",
        " cleaned_sent = normalize('NFD', sentence).encode('ascii', \\\n",
        " 'ignore')\n",
        " cleaned_sent = cleaned_sent.decode('UTF-8')\n",
        " cleaned_sent = cleaned_sent.split()\n",
        " cleaned_sent = [word.lower() for word in cleaned_sent]\n",
        " cleaned_sent = [word.translate(table) for word in cleaned_sent]\n",
        " cleaned_sent = [re_print.sub('', w) for w in cleaned_sent]\n",
        " cleaned_sent = [word for word in cleaned_sent if \\\n",
        " word.isalpha()]\n",
        " return ' '.join(cleaned_sent)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS84GGOaEfB0"
      },
      "source": [
        "def build_clean_english_french_sentences(english_sentences,\n",
        "french_sentences):\n",
        " french_sentences_cleaned = []\n",
        " english_sentences_cleaned = []\n",
        " for sent in french_sentences:\n",
        "  french_sentences_cleaned.append(clean_sentences(sent))\n",
        " for sent in english_sentences:\n",
        "  english_sentences_cleaned.append(clean_sentences(sent))\n",
        " return english_sentences_cleaned, french_sentences_cleaned\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZgjPKfXEr5O"
      },
      "source": [
        "#apply the functions\n",
        "english_sentences_cleaned, french_sentences_cleaned = build_clean_english_french_sentences(english_sentences,\n",
        "                                                                                           french_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8-xBKknLBRL"
      },
      "source": [
        "In the previous steps we cleaned the data and now its time to divide into train and target and portion of our data for testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iySXQuZAVyu8"
      },
      "source": [
        "def build_data(english_sentences_cleaned,french_sentences_cleaned):\n",
        "  input_dataset = []\n",
        "  target_dataset = []\n",
        "  input_characters = set()\n",
        "  target_characters = set()\n",
        "  for french_sentence in french_sentences_cleaned:\n",
        "    input_datapoint = french_sentence\n",
        "    input_dataset.append(input_datapoint)\n",
        "    for char in input_datapoint:\n",
        "      input_characters.add(char)\n",
        "  for english_sentence in english_sentences_cleaned:\n",
        "    target_datapoint = \"\\t\" + english_sentence + \"\\n\"\n",
        "    target_dataset.append(target_datapoint)\n",
        "    for char in target_datapoint:\n",
        "      target_characters.add(char)\n",
        "  return input_dataset, target_dataset,sorted(list(input_characters)),sorted(list(target_characters))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bdWQ2Dw3eEy"
      },
      "source": [
        "#calling the function to have input data, input char, output data, and output char\n",
        "input_dataset, target_dataset, input_characters, target_characters = \\\n",
        "build_data(english_sentences_cleaned,french_sentences_cleaned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxKZycefOsbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "647b9a09-1f2a-4a94-fde2-a53cb4d5fa64"
      },
      "source": [
        "#print the datasets we have\n",
        "print(\"input_dataset: \",input_dataset[:5])\n",
        "print('---'*20)\n",
        "print('target_dataset: ',target_dataset[10:15])\n",
        "print('---'*20)\n",
        "print('input_characters: ',input_characters[:5])\n",
        "print('----'*20)\n",
        "print('target_characters: ',target_characters[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_dataset:  ['va', 'cours', 'courez', 'ca alors', 'au feu']\n",
            "------------------------------------------------------------\n",
            "target_dataset:  ['\\twait\\n', '\\twait\\n', '\\ti see\\n', '\\ti try\\n', '\\ti won\\n']\n",
            "------------------------------------------------------------\n",
            "input_characters:  [' ', 'a', 'b', 'c', 'd']\n",
            "--------------------------------------------------------------------------------\n",
            "target_characters:  ['\\t', '\\n', ' ', 'a', 'b']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z8wLBSnxmJp"
      },
      "source": [
        "We have cleaned our data and we broke everything down to character. for the output character we included \\t and \\n indicating the start and end of input for the decoder. next we are giong to create some metadata from our input and target variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvalUrx9VVq2"
      },
      "source": [
        "def build_metadata(input_dataset, target_dataset, input_characters, target_characters):\n",
        "  num_Encoder_tokens = len(input_characters)\n",
        "  num_Decoder_tokens = len(target_characters)\n",
        "  max_Encoder_seq_length = max([len(data_point) for data_point in input_dataset])\n",
        "  max_Decoder_seq_length = max([len(data_point) for data_point in target_dataset])\n",
        "  print('Number of data points:', len(input_dataset))\n",
        "  print('Number of unique input tokens:', num_Encoder_tokens)\n",
        "  print('Number of unique output tokens', num_Decoder_tokens)\n",
        "  print('Max sequence length for inputs:', max_Encoder_seq_length)\n",
        "  print('Max sequence length for outputs', max_Decoder_seq_length)\n",
        "  return num_Encoder_tokens, num_Decoder_tokens, max_Encoder_seq_length, max_Decoder_seq_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo_5nIdJOxuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4269a4-a4db-4624-bdb7-5f9c7057d0dc"
      },
      "source": [
        "num_Encoder_tokens, num_Decoder_tokens, max_Encoder_seq_length, max_Decoder_seq_length =\\\n",
        "build_metadata(input_dataset,target_dataset,input_characters,target_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data points: 140000\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens 29\n",
            "Max sequence length for inputs: 117\n",
            "Max sequence length for outputs 58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bUs_e4e1ToN"
      },
      "source": [
        "Building a map from characters to indices and vice-versa\n",
        "\n",
        "**Represent** our input characters as indices\n",
        "\n",
        "**Convert** the indices into characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAR-Oy3C0aPB"
      },
      "source": [
        "#building index for each char and vice-versa\n",
        "def build_indices(input_characters, target_characters):\n",
        "  input_char_to_idx = {}\n",
        "  input_idx_to_char = {}\n",
        "  target_char_to_idx = {}\n",
        "  target_idx_to_char = {}\n",
        "\n",
        "  for i,char in enumerate(input_characters):\n",
        "    input_char_to_idx[char] = i\n",
        "    input_idx_to_char[i] = char\n",
        "  for i,char in enumerate(target_characters):\n",
        "    target_char_to_idx[char] = i\n",
        "    target_idx_to_char[i] = char\n",
        "\n",
        "  return input_char_to_idx, input_idx_to_char, target_char_to_idx, target_idx_to_char"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZnhi1622UjC"
      },
      "source": [
        "input_char_to_idx, input_idx_to_char, target_char_to_idx, target_idx_to_char = \\\n",
        "build_indices(input_characters, target_characters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CBvLCb42sSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e65df46b-a6a9-43b6-8d99-635daa9af3cb"
      },
      "source": [
        "#print the values\n",
        "print('input_char_to_idx:', input_char_to_idx)\n",
        "print('---'*50)\n",
        "print('input_idx_to_char:', input_idx_to_char)\n",
        "print('---'*50)\n",
        "print('target_char_to_idx:', target_char_to_idx)\n",
        "print('---'*50)\n",
        "print('target_idx_to_char:', target_idx_to_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_char_to_idx: {' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "input_idx_to_char: {0: ' ', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "target_char_to_idx: {'\\t': 0, '\\n': 1, ' ': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "target_idx_to_char: {0: '\\t', 1: '\\n', 2: ' ', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXaFYWGB3Y1r"
      },
      "source": [
        "#we are building our data structure to feed to the neural network\n",
        "def build_data_structures(length_input_dataset,max_Encoder_seq_length,max_Decoder_seq_length,\n",
        "                          num_Encoder_tokens,num_Decoder_tokens):\n",
        "  Encoder_input_data = np.zeros((length_input_dataset,max_Encoder_seq_length,num_Encoder_tokens),dtype='float32')\n",
        "  Decoder_input_data = np.zeros((length_input_dataset,max_Decoder_seq_length, num_Decoder_tokens),dtype='float32')\n",
        "  Decoder_target_data = np.zeros((length_input_dataset,max_Decoder_seq_length, num_Decoder_tokens),dtype='float32')\n",
        "  print(\"Dimensionality of Encoder input data is : \", \\\n",
        "  Encoder_input_data.shape)\n",
        "  print(\"Dimensionality of Decoder input data is : \", \\\n",
        "  Decoder_input_data.shape)\n",
        "  print(\"Dimensionality of Decoder target data is : \", \\\n",
        "  Decoder_target_data.shape)\n",
        "  return Encoder_input_data, Decoder_input_data, \\\n",
        "  Decoder_target_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gKaPeRC4_Lr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f951d55-84cc-415b-fb73-3db274ea3b4f"
      },
      "source": [
        "Encoder_input_data, Decoder_input_data, Decoder_target_data = \\\n",
        "build_data_structures(len(input_dataset),max_Encoder_seq_length, max_Decoder_seq_length,\n",
        "                      num_Encoder_tokens, num_Decoder_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensionality of Encoder input data is :  (140000, 117, 27)\n",
            "Dimensionality of Decoder input data is :  (140000, 58, 29)\n",
            "Dimensionality of Decoder target data is :  (140000, 58, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7SbTg9NBZVB"
      },
      "source": [
        "def add_data_to_data_structures(input_dataset, target_dataset,Encoder_input_data, Decoder_input_data, Decoder_target_data):\n",
        "  for i, (input_data_point, target_data_point) in enumerate(zip(input_dataset, target_dataset)):\n",
        "    for t, char in enumerate(input_data_point):\n",
        "      Encoder_input_data[i, t, input_char_to_idx[char]] = 1.\n",
        "    for t, char in enumerate(target_data_point):\n",
        "      Decoder_input_data[i, t, target_char_to_idx[char]] = 1.\n",
        "      if t > 0:\n",
        "      # Decoder_target_data will be ahead by one timestep\n",
        "      # and will not include the start character.\n",
        "        Decoder_target_data[i, t - 1, target_char_to_idx[char]] = 1.\n",
        "  return Encoder_input_data, Decoder_input_data, Decoder_target_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjB3CNTkCahW"
      },
      "source": [
        "Encoder_input_data, Decoder_input_data, Decoder_target_data = add_data_to_data_structures(input_dataset, target_dataset,\n",
        "                                                                                          Encoder_input_data, Decoder_input_data,\n",
        "                                                                                          Decoder_target_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZhFHiboDV5w"
      },
      "source": [
        "#lets define the hyperparameters\n",
        "batch_size = 200\n",
        "epochs = 100\n",
        "latent_dim = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seeh8vNaEGv6"
      },
      "source": [
        "#Encoder\n",
        "Encoder_inputs = Input(shape=(None,num_Encoder_tokens))\n",
        "Encoder = LSTM(latent_dim,return_state=True)\n",
        "Encoder_outputs, state_h, state_c = Encoder(Encoder_inputs)\n",
        "Encoder_states = [state_h,state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9vpiviEE28R"
      },
      "source": [
        "#Decoder\n",
        "Decoder_inputs = Input(shape=(None,num_Decoder_tokens))\n",
        "Decoder_lstm = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
        "Decoder_outputs, _, _ = Decoder_lstm(Decoder_inputs,initial_state=Encoder_states)\n",
        "Decoder_dense = Dense(num_Decoder_tokens, activation='softmax')\n",
        "Decoder_outputs = Decoder_dense(Decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKu7nyQKGWhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98941c9-24dc-461c-ede8-5ce454ae3a77"
      },
      "source": [
        "model = Model(inputs=[Encoder_inputs,Decoder_inputs],\n",
        "              outputs=Decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 27)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 29)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 290816      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  292864      input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 29)     7453        lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 591,133\n",
            "Trainable params: 591,133\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oytee2l-G0wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2034f1c2-9704-41e7-8e3b-55b725961dc2"
      },
      "source": [
        "model.fit([Encoder_input_data, Decoder_input_data],\n",
        "          Decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/560 [..............................] - ETA: 22s - loss: 1.4598 - accuracy: 0.0907WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0174s vs `on_train_batch_end` time: 0.0462s). Check your callbacks.\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.9411 - accuracy: 0.1534 - val_loss: 1.4474 - val_accuracy: 0.3148\n",
            "Epoch 2/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.6935 - accuracy: 0.2187 - val_loss: 1.2908 - val_accuracy: 0.3585\n",
            "Epoch 3/100\n",
            "560/560 [==============================] - 23s 42ms/step - loss: 0.6014 - accuracy: 0.2452 - val_loss: 1.1893 - val_accuracy: 0.3881\n",
            "Epoch 4/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.5514 - accuracy: 0.2597 - val_loss: 1.1292 - val_accuracy: 0.4089\n",
            "Epoch 5/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.5200 - accuracy: 0.2688 - val_loss: 1.0482 - val_accuracy: 0.4347\n",
            "Epoch 6/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.4946 - accuracy: 0.2770 - val_loss: 1.0089 - val_accuracy: 0.4475\n",
            "Epoch 7/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.4731 - accuracy: 0.2834 - val_loss: 0.9871 - val_accuracy: 0.4539\n",
            "Epoch 8/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.4514 - accuracy: 0.2901 - val_loss: 0.9965 - val_accuracy: 0.4539\n",
            "Epoch 9/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.4351 - accuracy: 0.2956 - val_loss: 0.9659 - val_accuracy: 0.4639\n",
            "Epoch 10/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.4211 - accuracy: 0.3003 - val_loss: 0.9580 - val_accuracy: 0.4669\n",
            "Epoch 11/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.4116 - accuracy: 0.3031 - val_loss: 0.9572 - val_accuracy: 0.4692\n",
            "Epoch 12/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.4073 - accuracy: 0.3044 - val_loss: 0.9304 - val_accuracy: 0.4739\n",
            "Epoch 13/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.4106 - accuracy: 0.3031 - val_loss: 0.9128 - val_accuracy: 0.4762\n",
            "Epoch 14/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.4002 - accuracy: 0.3057 - val_loss: 0.8998 - val_accuracy: 0.4821\n",
            "Epoch 15/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3860 - accuracy: 0.3107 - val_loss: 0.9106 - val_accuracy: 0.4817\n",
            "Epoch 16/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3770 - accuracy: 0.3141 - val_loss: 0.9240 - val_accuracy: 0.4806\n",
            "Epoch 17/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3773 - accuracy: 0.3137 - val_loss: 0.9264 - val_accuracy: 0.4795\n",
            "Epoch 18/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3720 - accuracy: 0.3153 - val_loss: 0.9315 - val_accuracy: 0.4797\n",
            "Epoch 19/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3671 - accuracy: 0.3168 - val_loss: 0.9173 - val_accuracy: 0.4831\n",
            "Epoch 20/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3632 - accuracy: 0.3181 - val_loss: 0.9532 - val_accuracy: 0.4719\n",
            "Epoch 21/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3614 - accuracy: 0.3184 - val_loss: 0.9400 - val_accuracy: 0.4795\n",
            "Epoch 22/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3568 - accuracy: 0.3202 - val_loss: 0.9510 - val_accuracy: 0.4775\n",
            "Epoch 23/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3515 - accuracy: 0.3218 - val_loss: 0.9193 - val_accuracy: 0.4857\n",
            "Epoch 24/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3483 - accuracy: 0.3228 - val_loss: 0.9421 - val_accuracy: 0.4818\n",
            "Epoch 25/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3476 - accuracy: 0.3229 - val_loss: 0.9443 - val_accuracy: 0.4800\n",
            "Epoch 26/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3456 - accuracy: 0.3235 - val_loss: 0.9564 - val_accuracy: 0.4785\n",
            "Epoch 27/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3432 - accuracy: 0.3244 - val_loss: 0.9683 - val_accuracy: 0.4764\n",
            "Epoch 28/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3422 - accuracy: 0.3247 - val_loss: 0.9574 - val_accuracy: 0.4794\n",
            "Epoch 29/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3389 - accuracy: 0.3257 - val_loss: 0.9823 - val_accuracy: 0.4745\n",
            "Epoch 30/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3381 - accuracy: 0.3260 - val_loss: 0.9512 - val_accuracy: 0.4824\n",
            "Epoch 31/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3359 - accuracy: 0.3266 - val_loss: 0.9914 - val_accuracy: 0.4741\n",
            "Epoch 32/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3332 - accuracy: 0.3275 - val_loss: 0.9782 - val_accuracy: 0.4777\n",
            "Epoch 33/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3299 - accuracy: 0.3284 - val_loss: 0.9829 - val_accuracy: 0.4775\n",
            "Epoch 34/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3248 - accuracy: 0.3304 - val_loss: 0.9485 - val_accuracy: 0.4862\n",
            "Epoch 35/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3184 - accuracy: 0.3329 - val_loss: 0.9664 - val_accuracy: 0.4837\n",
            "Epoch 36/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3153 - accuracy: 0.3337 - val_loss: 0.9968 - val_accuracy: 0.4782\n",
            "Epoch 37/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3125 - accuracy: 0.3346 - val_loss: 0.9548 - val_accuracy: 0.4875\n",
            "Epoch 38/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3100 - accuracy: 0.3355 - val_loss: 0.9918 - val_accuracy: 0.4802\n",
            "Epoch 39/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3082 - accuracy: 0.3360 - val_loss: 0.9726 - val_accuracy: 0.4851\n",
            "Epoch 40/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3058 - accuracy: 0.3368 - val_loss: 0.9780 - val_accuracy: 0.4855\n",
            "Epoch 41/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3038 - accuracy: 0.3375 - val_loss: 0.9836 - val_accuracy: 0.4840\n",
            "Epoch 42/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3019 - accuracy: 0.3380 - val_loss: 0.9840 - val_accuracy: 0.4850\n",
            "Epoch 43/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.3002 - accuracy: 0.3385 - val_loss: 0.9665 - val_accuracy: 0.4884\n",
            "Epoch 44/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2985 - accuracy: 0.3391 - val_loss: 0.9964 - val_accuracy: 0.4826\n",
            "Epoch 45/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2969 - accuracy: 0.3395 - val_loss: 1.0085 - val_accuracy: 0.4812\n",
            "Epoch 46/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2954 - accuracy: 0.3400 - val_loss: 1.0193 - val_accuracy: 0.4800\n",
            "Epoch 47/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2939 - accuracy: 0.3405 - val_loss: 0.9979 - val_accuracy: 0.4847\n",
            "Epoch 48/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2925 - accuracy: 0.3409 - val_loss: 1.0024 - val_accuracy: 0.4836\n",
            "Epoch 49/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2912 - accuracy: 0.3414 - val_loss: 1.0117 - val_accuracy: 0.4823\n",
            "Epoch 50/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2898 - accuracy: 0.3417 - val_loss: 1.0077 - val_accuracy: 0.4836\n",
            "Epoch 51/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2886 - accuracy: 0.3421 - val_loss: 1.0377 - val_accuracy: 0.4790\n",
            "Epoch 52/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2874 - accuracy: 0.3425 - val_loss: 1.0178 - val_accuracy: 0.4827\n",
            "Epoch 53/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2861 - accuracy: 0.3428 - val_loss: 1.0217 - val_accuracy: 0.4831\n",
            "Epoch 54/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2849 - accuracy: 0.3433 - val_loss: 1.0197 - val_accuracy: 0.4832\n",
            "Epoch 55/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2839 - accuracy: 0.3435 - val_loss: 1.0237 - val_accuracy: 0.4843\n",
            "Epoch 56/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2827 - accuracy: 0.3438 - val_loss: 1.0099 - val_accuracy: 0.4852\n",
            "Epoch 57/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2816 - accuracy: 0.3443 - val_loss: 1.0274 - val_accuracy: 0.4830\n",
            "Epoch 58/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2807 - accuracy: 0.3445 - val_loss: 1.0236 - val_accuracy: 0.4842\n",
            "Epoch 59/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2798 - accuracy: 0.3448 - val_loss: 1.0322 - val_accuracy: 0.4832\n",
            "Epoch 60/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2787 - accuracy: 0.3452 - val_loss: 1.0507 - val_accuracy: 0.4803\n",
            "Epoch 61/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2777 - accuracy: 0.3454 - val_loss: 1.0448 - val_accuracy: 0.4811\n",
            "Epoch 62/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2769 - accuracy: 0.3458 - val_loss: 1.0407 - val_accuracy: 0.4825\n",
            "Epoch 63/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2759 - accuracy: 0.3461 - val_loss: 1.0713 - val_accuracy: 0.4779\n",
            "Epoch 64/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2749 - accuracy: 0.3463 - val_loss: 1.0405 - val_accuracy: 0.4828\n",
            "Epoch 65/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2741 - accuracy: 0.3466 - val_loss: 1.0562 - val_accuracy: 0.4811\n",
            "Epoch 66/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2732 - accuracy: 0.3468 - val_loss: 1.0484 - val_accuracy: 0.4826\n",
            "Epoch 67/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2724 - accuracy: 0.3470 - val_loss: 1.0592 - val_accuracy: 0.4810\n",
            "Epoch 68/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2716 - accuracy: 0.3474 - val_loss: 1.0534 - val_accuracy: 0.4827\n",
            "Epoch 69/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2708 - accuracy: 0.3476 - val_loss: 1.0699 - val_accuracy: 0.4804\n",
            "Epoch 70/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2700 - accuracy: 0.3479 - val_loss: 1.0886 - val_accuracy: 0.4779\n",
            "Epoch 71/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2692 - accuracy: 0.3481 - val_loss: 1.0773 - val_accuracy: 0.4790\n",
            "Epoch 72/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2685 - accuracy: 0.3484 - val_loss: 1.0558 - val_accuracy: 0.4833\n",
            "Epoch 73/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2677 - accuracy: 0.3485 - val_loss: 1.0845 - val_accuracy: 0.4787\n",
            "Epoch 74/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2677 - accuracy: 0.3486 - val_loss: 1.0989 - val_accuracy: 0.4766\n",
            "Epoch 75/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2757 - accuracy: 0.3461 - val_loss: 1.0760 - val_accuracy: 0.4794\n",
            "Epoch 76/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2698 - accuracy: 0.3478 - val_loss: 1.0876 - val_accuracy: 0.4776\n",
            "Epoch 77/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2672 - accuracy: 0.3487 - val_loss: 1.0805 - val_accuracy: 0.4801\n",
            "Epoch 78/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2659 - accuracy: 0.3492 - val_loss: 1.0901 - val_accuracy: 0.4789\n",
            "Epoch 79/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2650 - accuracy: 0.3494 - val_loss: 1.1096 - val_accuracy: 0.4767\n",
            "Epoch 80/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2643 - accuracy: 0.3496 - val_loss: 1.0644 - val_accuracy: 0.4830\n",
            "Epoch 81/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2638 - accuracy: 0.3498 - val_loss: 1.1101 - val_accuracy: 0.4759\n",
            "Epoch 82/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2629 - accuracy: 0.3500 - val_loss: 1.1075 - val_accuracy: 0.4768\n",
            "Epoch 83/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2623 - accuracy: 0.3502 - val_loss: 1.0913 - val_accuracy: 0.4798\n",
            "Epoch 84/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2617 - accuracy: 0.3504 - val_loss: 1.0912 - val_accuracy: 0.4798\n",
            "Epoch 85/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2611 - accuracy: 0.3505 - val_loss: 1.1209 - val_accuracy: 0.4756\n",
            "Epoch 86/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2606 - accuracy: 0.3508 - val_loss: 1.1035 - val_accuracy: 0.4789\n",
            "Epoch 87/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2598 - accuracy: 0.3509 - val_loss: 1.1171 - val_accuracy: 0.4766\n",
            "Epoch 88/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2591 - accuracy: 0.3512 - val_loss: 1.0787 - val_accuracy: 0.4830\n",
            "Epoch 89/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2585 - accuracy: 0.3513 - val_loss: 1.1000 - val_accuracy: 0.4793\n",
            "Epoch 90/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2578 - accuracy: 0.3515 - val_loss: 1.1373 - val_accuracy: 0.4743\n",
            "Epoch 91/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2573 - accuracy: 0.3517 - val_loss: 1.1255 - val_accuracy: 0.4765\n",
            "Epoch 92/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2568 - accuracy: 0.3519 - val_loss: 1.1117 - val_accuracy: 0.4789\n",
            "Epoch 93/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2581 - accuracy: 0.3515 - val_loss: 1.1103 - val_accuracy: 0.4786\n",
            "Epoch 94/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2607 - accuracy: 0.3506 - val_loss: 1.0926 - val_accuracy: 0.4806\n",
            "Epoch 95/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2578 - accuracy: 0.3515 - val_loss: 1.1008 - val_accuracy: 0.4805\n",
            "Epoch 96/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2551 - accuracy: 0.3525 - val_loss: 1.1329 - val_accuracy: 0.4761\n",
            "Epoch 97/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2547 - accuracy: 0.3525 - val_loss: 1.0945 - val_accuracy: 0.4807\n",
            "Epoch 98/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2541 - accuracy: 0.3527 - val_loss: 1.0907 - val_accuracy: 0.4821\n",
            "Epoch 99/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2536 - accuracy: 0.3529 - val_loss: 1.0939 - val_accuracy: 0.4821\n",
            "Epoch 100/100\n",
            "560/560 [==============================] - 23s 41ms/step - loss: 0.2531 - accuracy: 0.3531 - val_loss: 1.1143 - val_accuracy: 0.4786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe1200bd4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOMwVrnnQ01_"
      },
      "source": [
        "model.save('neural_machine_translation_french_to_english.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GEIJwlvRM-A"
      },
      "source": [
        "The model is trained and saved. now the next step is to find a way to infer from the model we build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpFS-ANsRV4m"
      },
      "source": [
        "Encoder_model = Model(Encoder_inputs, Encoder_states)\n",
        "Decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "Decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "Decoder_states_inputs = [Decoder_state_input_h,Decoder_state_input_c]\n",
        "Decoder_outputs, state_h, state_c = Decoder_lstm(Decoder_inputs,initial_state=Decoder_states_inputs)\n",
        "Decoder_states = [state_h, state_c]\n",
        "Decoder_outputs = Decoder_dense(Decoder_outputs)\n",
        "Decoder_model = Model([Decoder_inputs] + Decoder_states_inputs,[Decoder_outputs] + Decoder_states)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9qm9GniSklM"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  states_value = Encoder_model.predict(input_seq)\n",
        "\n",
        "  target_seq = np.zeros((1,1,num_Decoder_tokens))\n",
        "  target_seq[0, 0, target_char_to_idx['\\t']] = 1.\n",
        "\n",
        "  stop_condition=False\n",
        "  decoded_sentence = ' '\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = Decoder_model.predict([target_seq]+states_value)\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = target_idx_to_char[sampled_token_index]\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    if(sampled_char =='\\n' or len(decoded_sentence) > max_Decoder_seq_length):\n",
        "      stop_condition = True\n",
        "    \n",
        "    target_seq = np.zeros((1, 1, num_Decoder_tokens))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "    states_value = [h, c]\n",
        "  return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1puvBwERWlpP"
      },
      "source": [
        "#lets translate\n",
        "def decode(seq_index):\n",
        " input_seq = Encoder_input_data[seq_index: seq_index + 1]\n",
        " decoded_sentence = decode_sequence(input_seq)\n",
        " print('-')\n",
        " print('Input sentence:', input_dataset[seq_index])\n",
        " print('Decoded sentence:', decoded_sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WenhdGJRW1QG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf31018-2528-4344-c5bc-1062d89ee916"
      },
      "source": [
        "for i in range(130000,130020):\n",
        "  print(decode(i))\n",
        "  print(target_dataset[i])\n",
        "  print('----'*50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: si vous ne voulez pas le faire vous ny etes pas oblige\n",
            "Decoded sentence:  if you dont want to do anything for\n",
            "\n",
            "None\n",
            "\tif you dont want to do it you dont have to\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si tu ne veux pas le faire tu ny es pas obligee\n",
            "Decoded sentence:  if you dont want to do anything for\n",
            "\n",
            "None\n",
            "\tif you dont want to do it you dont have to\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si vous ne voulez pas le faire vous ny etes pas obliges\n",
            "Decoded sentence:  if you dont want to do anything for\n",
            "\n",
            "None\n",
            "\tif you dont want to do it you dont have to\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si vous ne voulez pas le faire vous ny etes pas obligee\n",
            "Decoded sentence:  if you dont want to do anything for\n",
            "\n",
            "None\n",
            "\tif you dont want to do it you dont have to\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si vous ne voulez pas le faire vous ny etes pas obligees\n",
            "Decoded sentence:  if you dont want to do anything for\n",
            "\n",
            "None\n",
            "\tif you dont want to do it you dont have to\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si vous trouvez une erreur merci de laisser un commentaire\n",
            "Decoded sentence:  if you want that i can take it that but\n",
            "\n",
            "None\n",
            "\tif you find a mistake please leave a comment\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si vous approchez dun chameau vous risquez detre mordu\n",
            "Decoded sentence:  if you cant beat that doge off\n",
            "\n",
            "None\n",
            "\tif you go near a camel you risk being bitten\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si vous prenez ce remede vous vous sentirez mieux\n",
            "Decoded sentence:  if you want that i can take it that bus\n",
            "\n",
            "None\n",
            "\tif you take this medicine youll feel better\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si tu prends ce remede tu te sentiras mieux\n",
            "Decoded sentence:  if you cant bear you id better talk\n",
            "\n",
            "None\n",
            "\tif you take this medicine youll feel better\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si tu en veux une il te faudra trouver la tienne\n",
            "Decoded sentence:  if you dont want to do anything for\n",
            "\n",
            "None\n",
            "\tif you want one youll have to find your own\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si vous en voulez une il vous faudra trouver la votre\n",
            "Decoded sentence:  if you cant beat that doge off\n",
            "\n",
            "None\n",
            "\tif you want one youll have to find your own\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si vous en voulez un il vous faudra trouver le votre\n",
            "Decoded sentence:  if you want that i can tell me that scrice\n",
            "\n",
            "None\n",
            "\tif you want one youll have to find your own\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si tu en veux un il te faudra trouver le tien\n",
            "Decoded sentence:  if you dont want to do anything for\n",
            "\n",
            "None\n",
            "\tif you want one youll have to find your own\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: si ta dent te fait mal tu devrais aller voir un dentiste\n",
            "Decoded sentence:  if you dont want to do anything for\n",
            "\n",
            "None\n",
            "\tif your tooth hurts you should see a dentist\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: limagination affecte tous les aspects de notre vie\n",
            "Decoded sentence:  one is the real person i want to\n",
            "\n",
            "None\n",
            "\timagination affects every aspect of our lives\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: au japon la nouvelle annee scolaire commence en avril\n",
            "Decoded sentence:  when i make sense not to catch the bus\n",
            "\n",
            "None\n",
            "\tin japan the new school year begins in april\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: au cas ou il se passe quoi que ce soit telephonemoi immediatement\n",
            "Decoded sentence:  in austral a woman stude his watch stole\n",
            "\n",
            "None\n",
            "\tin case anything happens call me immediately\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: au cas ou il se passe quoi que ce soit telephonezmoi immediatement\n",
            "Decoded sentence:  in austral a woman stude his watch stole\n",
            "\n",
            "None\n",
            "\tin case anything happens call me immediately\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: en fait linverse est davantage susceptible de se produire\n",
            "Decoded sentence:  actually im staying at the mountains\n",
            "\n",
            "None\n",
            "\tin fact the opposite is more likely to occur\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "-\n",
            "Input sentence: par temps chaud leau sevapore plus rapidement\n",
            "Decoded sentence:  after the store seemed to watch tv\n",
            "\n",
            "None\n",
            "\tin hot weather water evaporates more quickly\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}